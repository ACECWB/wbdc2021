{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efee3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\"\"\"\n",
    "Author:\n",
    "    zanshuxun, zanshuxun@aliyun.com\n",
    "    songwei, magic_24k@163.com\n",
    "\n",
    "Reference:\n",
    "    [1] [Jiaqi Ma, Zhe Zhao, Xinyang Yi, et al. Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts[C]](https://dl.acm.org/doi/10.1145/3219819.3220007)\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from deepctr_torch.models.basemodel import BaseModel\n",
    "from deepctr_torch.inputs import combined_dnn_input, embedding_lookup, maxlen_lookup\n",
    "from deepctr_torch.layers import DNN, PredictionLayer, CIN, concat_fun, InteractingLayer\n",
    "from deepctr_torch.layers.sequence import AttentionSequencePoolingLayer\n",
    "import pandas as pd\n",
    "\n",
    "class MMOELayer(nn.Module):\n",
    "    \"\"\"\n",
    "    The Multi-gate Mixture-of-Experts layer in MMOE model\n",
    "      Input shape\n",
    "        - 2D tensor with shape: ``(batch_size,units)``.\n",
    "\n",
    "      Output shape\n",
    "        - A list with **num_tasks** elements, which is a 2D tensor with shape: ``(batch_size, output_dim)`` .\n",
    "\n",
    "      Arguments\n",
    "        - **input_dim** : Positive integer, dimensionality of input features.\n",
    "        - **num_tasks**: integer, the number of tasks, equal to the number of outputs.\n",
    "        - **num_experts**: integer, the number of experts.\n",
    "        - **output_dim**: integer, the dimension of each output of MMOELayer.\n",
    "\n",
    "    References\n",
    "      - [Jiaqi Ma, Zhe Zhao, Xinyang Yi, et al. Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts[C]](https://dl.acm.org/doi/10.1145/3219819.3220007)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, num_tasks, num_experts, output_dim):\n",
    "        super(MMOELayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_experts = num_experts\n",
    "        self.num_tasks = num_tasks\n",
    "        self.output_dim = output_dim\n",
    "        self.expert_network = nn.Linear(self.input_dim, self.num_experts * self.output_dim, bias=True)\n",
    "        self.gating_networks = nn.ModuleList(\n",
    "            [nn.Linear(self.input_dim, self.num_experts, bias=False) for _ in range(self.num_tasks)])\n",
    "        # initial model\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        expert_out = self.expert_network(inputs)\n",
    "        expert_out = expert_out.reshape([-1, self.output_dim, self.num_experts])\n",
    "        for i in range(self.num_tasks):\n",
    "            gate_out = self.gating_networks[i](inputs)\n",
    "            gate_out = gate_out.softmax(1).unsqueeze(-1)\n",
    "            output = torch.bmm(expert_out, gate_out).squeeze()\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MMOE(BaseModel):\n",
    "    \"\"\"Instantiates the Multi-gate Mixture-of-Experts architecture.\n",
    "\n",
    "    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n",
    "    :param num_tasks: integer, number of tasks, equal to number of outputs, must be greater than 1.\n",
    "    :param tasks: list of str, indicating the loss of each tasks, ``\"binary\"`` for  binary logloss, ``\"regression\"`` for regression loss. e.g. ['binary', 'regression']\n",
    "    :param num_experts: integer, number of experts.\n",
    "    :param expert_dim: integer, the hidden units of each expert.\n",
    "    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of shared-bottom DNN\n",
    "    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n",
    "    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n",
    "    :param init_std: float,to use as the initialize std of embedding vector\n",
    "    :param task_dnn_units: list,list of positive integer or empty list, the layer number and units in each layer of task-specific DNN\n",
    "    :param seed: integer ,to use as random seed.\n",
    "    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n",
    "    :param dnn_activation: Activation function to use in DNN\n",
    "    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in DNN\n",
    "    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"``\n",
    "\n",
    "    :return: A PyTorch model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dnn_feature_columns, history_feature_list, num_tasks, tasks, num_experts=4, expert_dim=8, dnn_hidden_units=(128, 128),\n",
    "                 l2_reg_embedding=1e-5, l2_reg_dnn=0, init_std=0.0001, task_dnn_units=None, seed=1024, dnn_dropout=0,\n",
    "                 dnn_activation='relu', dnn_use_bn=False, device='cpu', gpus=[0, 1]):\n",
    "        \n",
    "        super(MMOE, self).__init__(linear_feature_columns=[], dnn_feature_columns=dnn_feature_columns,\n",
    "                                   l2_reg_embedding=l2_reg_embedding, seed=seed, device=device)\n",
    "        if num_tasks <= 1:\n",
    "            raise ValueError(\"num_tasks must be greater than 1\")\n",
    "        if len(tasks) != num_tasks:\n",
    "            raise ValueError(\"num_tasks must be equal to the length of tasks\")\n",
    "        for task in tasks:\n",
    "            if task not in ['binary', 'regression']:\n",
    "                raise ValueError(\"task must be binary or regression, {} is illegal\".format(task))\n",
    "        self.sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, SparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n",
    "        self.varlen_sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, VarLenSparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n",
    "        \n",
    "        # atten tag key\n",
    "        self.history_feature_list = history_feature_list\n",
    "        self.history_feature_columns = []\n",
    "        self.sparse_varlen_feature_columns = []\n",
    "        self.history_fc_names = list(map(lambda x: \"hist_\" + x, history_feature_list))\n",
    "        for fc in self.varlen_sparse_feature_columns:\n",
    "            feature_name = fc.name\n",
    "            if feature_name in self.history_fc_names:\n",
    "                self.history_feature_columns.append(fc)\n",
    "            else:\n",
    "                self.sparse_varlen_feature_columns.append(fc)\n",
    "        # din component\n",
    "#         att_emb_dim = self._compute_interest_dim()\n",
    "#         print(att_emb_dim)\n",
    "#         att_activation='Dice'\n",
    "#         att_weight_normalization=False\n",
    "#         att_hidden_size=(128, 128, 64)\n",
    "#         self.attention = AttentionSequencePoolingLayer(att_hidden_units=att_hidden_size,\n",
    "#                                                        embedding_dim=att_emb_dim,\n",
    "#                                                        att_activation=att_activation,\n",
    "#                                                        return_score=False,\n",
    "#                                                        supports_masking=False,\n",
    "#                                                        weight_normalization=att_weight_normalization)\n",
    "        \n",
    "        self.din_linear = nn.Linear(40, 1, bias=False).to(device)\n",
    "#         self.din_out = PredictionLayer('binary')\n",
    "        # MMOE\n",
    "        self.tasks = tasks\n",
    "        self.task_dnn_units = task_dnn_units\n",
    "        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n",
    "                       activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n",
    "                       init_std=init_std, device=device)\n",
    "#         self.before_mmoe = DNN(dnn_hidden_units[-1]+600+1200+12600-10800-1575, dnn_hidden_units,\n",
    "#                        activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n",
    "#                        init_std=init_std, device=device)\n",
    "        self.mmoe_layer = MMOELayer(dnn_hidden_units[-1]+600+1200+12600-10800-1575, num_tasks, num_experts, expert_dim)\n",
    "        if task_dnn_units is not None:\n",
    "            # the last layer of task_dnn should be expert_dim\n",
    "            self.task_dnn = nn.ModuleList([DNN(expert_dim, task_dnn_units+(expert_dim,)) for _ in range(num_tasks)])\n",
    "        self.tower_network = nn.ModuleList([nn.Linear(expert_dim, 1, bias=False) for _ in range(num_tasks)])\n",
    "        self.out = nn.ModuleList([PredictionLayer(task) for task in self.tasks])\n",
    "        self.to(device)\n",
    "        \n",
    "        # 加入cin\n",
    "        cin_layer_size=(256, 128, 64)\n",
    "        self.cin_layer_size=cin_layer_size\n",
    "        cin_split_half=True\n",
    "        cin_activation='relu'\n",
    "        l2_reg_cin=0\n",
    "        self.use_cin = len(self.cin_layer_size) > 0 and len(dnn_feature_columns) > 0\n",
    "        if self.use_cin:\n",
    "            field_num = len(self.sparse_feature_columns)\n",
    "            if cin_split_half == True:\n",
    "                self.featuremap_num = sum(\n",
    "                    cin_layer_size[:-1]) // 2 + cin_layer_size[-1]\n",
    "            else:\n",
    "                self.featuremap_num = sum(cin_layer_size)\n",
    "            self.cin = CIN(field_num, cin_layer_size,\n",
    "                           cin_activation, cin_split_half, l2_reg_cin, seed, device=device)\n",
    "            self.cin_linear = nn.Linear(self.featuremap_num, 1, bias=False).to(device)\n",
    "            self.add_regularization_weight(filter(lambda x: 'weight' in x[0], self.cin.named_parameters()),\n",
    "                                           l2=l2_reg_cin)\n",
    "        \n",
    "        # multi-head atten\n",
    "        att_embedding_size=15\n",
    "        att_head_num=15\n",
    "        att_layer_num=3\n",
    "        att_res=True\n",
    "        self.int_layers = nn.ModuleList(\n",
    "            [InteractingLayer(self.embedding_size if i == 0 else att_embedding_size * att_head_num,\n",
    "                              att_embedding_size, att_head_num, att_res, device=device) for i in range(att_layer_num)])\n",
    "        \n",
    "        print('sparse_features: ', self.sparse_feature_columns)\n",
    "        print('varlen_features: ', self.varlen_sparse_feature_columns)\n",
    "    \n",
    "    def _compute_interest_dim(self):\n",
    "        interest_dim = 0\n",
    "        for feat in self.sparse_feature_columns:\n",
    "            if feat.name in self.history_feature_list:\n",
    "                interest_dim += feat.embedding_dim\n",
    "        return interest_dim\n",
    "    \n",
    "    def forward(self, X):\n",
    "#         print(self.embedding_dict)\n",
    "        _, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n",
    "                                                                           self.embedding_dict)\n",
    "        sparse_embedding_list = embedding_lookup(X, self.embedding_dict, self.feature_index, self.sparse_feature_columns,\n",
    "                                              to_list=True)\n",
    "        # user tag_key atten\n",
    "#         query_emb_list = embedding_lookup(X, self.embedding_dict, self.feature_index, self.sparse_feature_columns,\n",
    "#                                           return_feat_list=self.history_feature_list, to_list=True)\n",
    "#         keys_emb_list = embedding_lookup(X, self.embedding_dict, self.feature_index, self.history_feature_columns,\n",
    "#                                          return_feat_list=self.history_fc_names, to_list=True)\n",
    "#         query_emb = torch.cat(query_emb_list, dim=-1)                     # [B, 1, E]\n",
    "#         keys_emb = torch.cat(keys_emb_list, dim=-1)                       # [B, T, E]\n",
    "#         keys_length_feature_name = [feat.length_name for feat in self.varlen_sparse_feature_columns if\n",
    "#                                     feat.length_name is not None]\n",
    "#         keys_length = torch.squeeze(maxlen_lookup(X, self.feature_index, keys_length_feature_name), 1)  # [B, 1]\n",
    "#         hist = self.attention(query_emb, keys_emb, keys_length)           # [B, 1, E]\n",
    "#         din_logit = self.din_linear(hist).squeeze(1)\n",
    "        \n",
    "        \n",
    "        # 加入cin模块\n",
    "        if self.use_cin:\n",
    "            cin_input = torch.cat(sparse_embedding_list, dim=1)\n",
    "            cin_output = self.cin(cin_input) # 1024, 256\n",
    "            cin_logit = self.cin_linear(cin_output)\n",
    "            \n",
    "#         print('cin_logit: ', cin_logit)  \n",
    "#         print('din_logit: ', din_logit, din_logit.shape)\n",
    "        # muti-head\n",
    "        att_input = concat_fun(sparse_embedding_list, axis=1)\n",
    "        for layer in self.int_layers:\n",
    "            att_input = layer(att_input)\n",
    "        att_output = torch.flatten(att_input, start_dim=1)\n",
    "        \n",
    "        dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list) # 1024, 101\n",
    "#         print('dnn_input: ', dnn_input.shape)\n",
    "#         print('hist: ', hist.shape)\n",
    "        dnn_input = torch.cat((dnn_input, hist.squeeze(1)), dim=-1)\n",
    "        dnn_output = self.dnn(dnn_input)\n",
    "        dnn_output = concat_fun([att_output, dnn_output])\n",
    "#         dnn_output = self.before_mmoe(dnn_output)\n",
    "        mmoe_outs = self.mmoe_layer(dnn_output)\n",
    "        if self.task_dnn_units is not None:\n",
    "            mmoe_outs = [self.task_dnn[i](mmoe_out) for i, mmoe_out in enumerate(mmoe_outs)]\n",
    "\n",
    "        task_outputs = []\n",
    "        for i, mmoe_out in enumerate(mmoe_outs):\n",
    "            logit = self.tower_network[i](mmoe_out) + cin_logit + din_logit\n",
    "            output = self.out[i](logit)\n",
    "            task_outputs.append(output)\n",
    "#         print(cin_logit.shape, din_logit.shape)\n",
    "#         print(task_outputs.shape)\n",
    "        task_outputs = torch.cat(task_outputs, -1)\n",
    "        return task_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d3767ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use features:  ['bgm_song_id', 'bgm_singer_id', 'userid', 'feedid', 'authorid', 'videoplayseconds', 'tagids', 'tag_seq_len', 'keyids', 'key_seq_len', 'user_embedding_normal', 'user_embedding_adjust']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import sys\n",
    "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "BASE_DIR = '.'\n",
    "sys.path.append(os.path.join(BASE_DIR, '../../config'))\n",
    "sys.path.append(os.path.join(BASE_DIR, '../model'))\n",
    "sys.path.append(os.path.join(BASE_DIR, '../utils'))\n",
    "from config import *\n",
    "from time import time\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names, VarLenSparseFeat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datatable as dt\n",
    "# from mmoe import MMOE\n",
    "from evaluation import evaluate_deepctr\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# 训练相关参数设置\n",
    "ONLINE_FLAG = False  # 是否准备线上提交\n",
    "\n",
    "# 指定GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "vocab_dict = {\n",
    "    'bgm_song_id': 25158+1,\n",
    "    'bgm_singer_id': 17499+1,\n",
    "    'userid': 199999,\n",
    "    'feedid': 112871+1,\n",
    "    'authorid': 18788+1,\n",
    "}\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "epochs = 1\n",
    "batch_size = 1024\n",
    "embedding_dim = 20\n",
    "target = ['read_comment', 'like', 'click_avatar', 'forward', 'comment', 'favorite', 'follow']\n",
    "tagids = ['manual_tag_' + str(tagid) for tagid in range(11)] # 11\n",
    "keyids = ['manual_key_' + str(keyid) for keyid in range(11)] # 18\n",
    "sparse_features = ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
    "dense_features = ['videoplayseconds', ]\n",
    "\n",
    "feed = dt.fread(FEED_INFO)\n",
    "feed = feed.to_pandas()\n",
    "tag = dt.fread(FEATURE_PATH + '/feed_info_tags_keys_des_seq_len.csv')\n",
    "tag = tag.to_pandas()[tagids + keyids + ['feedid', 'tag_seq_len', 'key_seq_len']]\n",
    "\n",
    "pkl = open(FEATURE_PATH + '/user_encoder.pkl', 'rb')\n",
    "userid_map = pickle.load(pkl)\n",
    "pkl.close()\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "user_emb1 = np.load(FEATURE_PATH + '/user_emb_normal.npy')\n",
    "user_emb1 = torch.from_numpy(user_emb1).float().to(device)\n",
    "user_emb2 = np.load(FEATURE_PATH + '/user_emb_adjust.npy')\n",
    "user_emb2 = torch.from_numpy(user_emb2).float().to(device)\n",
    "\n",
    "feed[[\"bgm_song_id\", \"bgm_singer_id\"]] += 1  # 0 用于填未知\n",
    "feed[[\"bgm_song_id\", \"bgm_singer_id\", \"videoplayseconds\"]] = \\\n",
    "    feed[[\"bgm_song_id\", \"bgm_singer_id\", \"videoplayseconds\"]].fillna(0)\n",
    "feed['bgm_song_id'] = feed['bgm_song_id'].astype('int64')\n",
    "feed['bgm_singer_id'] = feed['bgm_singer_id'].astype('int64')\n",
    "\n",
    "if ONLINE_FLAG:\n",
    "    data = pd.read_csv(USER_ACTION, iterator=True)\n",
    "else:\n",
    "    val = pd.read_csv(FEATURE_PATH + '/val_data.csv')\n",
    "    data = pd.read_csv(FEATURE_PATH + '/train_data.csv', iterator=True)\n",
    "\n",
    "\n",
    "\n",
    "#     fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].max() + 1, embedding_dim=embedding_dim)\n",
    "#                           for feat in sparse_features] + [DenseFeat(feat, 1) for feat in dense_features]\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=vocab_dict[feat] + 1, embedding_dim=embedding_dim)\n",
    "                      for feat in vocab_dict.keys()] + [DenseFeat(feat, 1) for feat in dense_features]\n",
    "fixlen_feature_columns += [VarLenSparseFeat(SparseFeat('tagids', vocabulary_size=350 + 1, embedding_dim=embedding_dim), 11, length_name='tag_seq_len')]\n",
    "fixlen_feature_columns += [VarLenSparseFeat(SparseFeat('keyids', vocabulary_size=23262 + 1, embedding_dim=embedding_dim), 11, length_name='key_seq_len')]\n",
    "# fixlen_feature_columns += [SparseFeat('tagids', vocabulary_size=200000, embedding_dim=embedding_dim)]\n",
    "# fixlen_feature_columns += [SparseFeat('keyids', vocabulary_size=200000, embedding_dim=embedding_dim)]\n",
    "\n",
    "# fixlen_feature_columns += [SparseFeat(feat, vocabulary_size=350 + 1, embedding_dim=embedding_dim)\n",
    "#                           for feat in tagids]\n",
    "# fixlen_feature_columns += [SparseFeat(feat, vocabulary_size=23262 + 1, embedding_dim=embedding_dim)\n",
    "#                           for feat in keyids]\n",
    "# fixlen_feature_columns += [SparseFeat('feed_embedding', 112871+1, embedding_dim=64)]\n",
    "fixlen_feature_columns += [SparseFeat('user_embedding_normal', 200000, embedding_dim=embedding_dim)]\n",
    "fixlen_feature_columns += [SparseFeat('user_embedding_adjust', 200000, embedding_dim=embedding_dim)]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(dnn_feature_columns)\n",
    "print('use features: ', feature_names)\n",
    "\n",
    "\n",
    "if ONLINE_FLAG:\n",
    "    # 加入test\n",
    "    test = dt.fread(TEST_FILE)\n",
    "    test = test.to_pandas()\n",
    "    test = test.merge(feed[['feedid', 'authorid', 'videoplayseconds', 'bgm_song_id', 'bgm_singer_id']], how='left',\n",
    "                      on='feedid')\n",
    "    test = test.merge(tag, how='left', on='feedid')\n",
    "    test[dense_features] = test[dense_features].fillna(0, )\n",
    "    test[dense_features] = mms.fit_transform(test[dense_features])\n",
    "    test['userid'] = userid_map.transform(test['userid'])\n",
    "\n",
    "    test_model_input = {name: test[name] for name in feature_names if name not in ['feed_embedding', 'user_embedding_normal', 'user_embedding_adjust', 'hist_tagids', 'hist_keyids', 'tagids', 'keyids']}\n",
    "    test_model_input['user_embedding_normal'] = test_model_input['userid']\n",
    "    test_model_input['user_embedding_adjust'] = test_model_input['userid']\n",
    "    test_model_input['tagids'] = test[['manual_tag_' + str(index) for index in range(11)]].values\n",
    "    test_model_input['keyids'] = test[['manual_key_' + str(index) for index in range(11)]].values\n",
    "else:\n",
    "    val = val.merge(feed[['feedid', 'authorid', 'videoplayseconds', 'bgm_song_id', 'bgm_singer_id']], how='left',\n",
    "                  on='feedid')\n",
    "    val = val.merge(tag, how='left', on='feedid')\n",
    "    val[dense_features] = val[dense_features].fillna(0, )\n",
    "    val[dense_features] = mms.fit_transform(val[dense_features])\n",
    "    val['userid'] = userid_map.transform(val['userid'])\n",
    "    val_model_input = {name: val[name] for name in feature_names if name not in ['hist_tagids', 'hist_keyids', 'feed_embedding', 'user_embedding_normal', 'user_embedding_adjust', 'tagids', 'keyids']}\n",
    "    val_model_input['tagids'] = val[['manual_tag_' + str(index) for index in range(11)]].values\n",
    "    val_model_input['keyids'] = val[['manual_key_' + str(index) for index in range(11)]].values\n",
    "#     val_model_input['tagids'] = val_model_input['userid']\n",
    "#     val_model_input['keyids'] = val_model_input['userid']\n",
    "    val_model_input['user_embedding_normal'] = val_model_input['userid']\n",
    "    val_model_input['user_embedding_adjust'] = val_model_input['userid']\n",
    "    userid_list = val['userid'].astype(str).tolist()\n",
    "    val_labels = [val[y].values for y in target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d457a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse_features:  [SparseFeat(name='bgm_song_id', vocabulary_size=25160, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='bgm_song_id', group_name='default_group'), SparseFeat(name='bgm_singer_id', vocabulary_size=17501, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='bgm_singer_id', group_name='default_group'), SparseFeat(name='userid', vocabulary_size=200000, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='userid', group_name='default_group'), SparseFeat(name='feedid', vocabulary_size=112873, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='feedid', group_name='default_group'), SparseFeat(name='authorid', vocabulary_size=18790, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='authorid', group_name='default_group'), SparseFeat(name='user_embedding_normal', vocabulary_size=200000, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='user_embedding_normal', group_name='default_group'), SparseFeat(name='user_embedding_adjust', vocabulary_size=200000, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='user_embedding_adjust', group_name='default_group')]\n",
      "varlen_features:  [VarLenSparseFeat(sparsefeat=SparseFeat(name='tagids', vocabulary_size=351, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='tagids', group_name='default_group'), maxlen=11, combiner='mean', length_name='tag_seq_len'), VarLenSparseFeat(sparsefeat=SparseFeat(name='keyids', vocabulary_size=23263, embedding_dim=20, use_hash=False, dtype='int32', embedding_name='keyids', group_name='default_group'), maxlen=11, combiner='mean', length_name='key_seq_len')]\n",
      "chunk:  1\n",
      "cuda\n",
      "Train on 10000000 samples, validate on 0 samples, 9766 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-84e564e03783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             history = train_model.fit(train_model_input, train_labels,\n\u001b[0;32m---> 36\u001b[0;31m                               batch_size=batch_size, epochs=1, verbose=1)\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mONLINE_FLAG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mval_pred_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-e22c903cd9c6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;31m#         print('dnn_input: ', dnn_input.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m#         print('hist: ', hist.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mdnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mdnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mdnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnn_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "train_model = MMOE(dnn_feature_columns, history_feature_list=[], num_tasks=7, num_experts=13, expert_dim=128, dnn_hidden_units=(128, 128, 64),\n",
    "                   task_dnn_units=(128, 128, 64),\n",
    "                   tasks=['binary', 'binary', 'binary', 'binary', 'binary', 'binary', 'binary'], device=device)\n",
    "train_model.compile(\"adagrad\", loss='binary_crossentropy')\n",
    "train_model.embedding_dict['user_embedding_normal'] = nn.Embedding.from_pretrained(user_emb1, freeze=False)\n",
    "train_model.embedding_dict['user_embedding_adjust'] = nn.Embedding.from_pretrained(user_emb2, freeze=False)\n",
    "train_model.embedding_dict['tagids'] = train_model.embedding_dict['keyids']\n",
    "\n",
    "loop = True\n",
    "cnt = 0\n",
    "while loop:\n",
    "    try:\n",
    "        cnt += 1\n",
    "        print('chunk: ', cnt)\n",
    "        train = data.get_chunk(1000*10000)\n",
    "        train = train.merge(feed[['feedid', 'authorid', 'videoplayseconds', 'bgm_song_id', 'bgm_singer_id']], how='left',\n",
    "                  on='feedid')\n",
    "        train = train.merge(tag, how='left', on='feedid')\n",
    "        train[dense_features] = train[dense_features].fillna(0, )\n",
    "        train[dense_features] = mms.fit_transform(train[dense_features])\n",
    "        train['userid'] = userid_map.transform(train['userid'])                \n",
    "\n",
    "        train_model_input = {name: train[name] for name in feature_names if name not in ['hist_tagids', 'hist_keyids', 'feed_embedding', 'user_embedding_normal', 'user_embedding_adjust', 'tagids', 'keyids']}\n",
    "        # train_model_input['feed_embedding'] = train_model_input['feedid']\n",
    "        # val_model_input['feed_embedding'] = val_model_input['feedid']\n",
    "        train_model_input['tagids'] = train[['manual_tag_' + str(index) for index in range(11)]].values\n",
    "        train_model_input['keyids'] = train[['manual_key_' + str(index) for index in range(11)]].values\n",
    "#         train_model_input['tagids'] = train_model_input['userid']\n",
    "#         train_model_input['keyids'] = train_model_input['userid']\n",
    "        train_model_input['user_embedding_normal'] = train_model_input['userid']\n",
    "        train_model_input['user_embedding_adjust'] = train_model_input['userid']\n",
    "        train_labels = train[target].values\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            history = train_model.fit(train_model_input, train_labels,\n",
    "                              batch_size=batch_size, epochs=1, verbose=1)\n",
    "        if not ONLINE_FLAG:\n",
    "            val_pred_ans = train_model.predict(val_model_input, batch_size=batch_size * 4)\n",
    "            # 模型predict()返回值格式为(?, 4)，与tf版mmoe不同。因此下方用到了transpose()进行变化。\n",
    "            evaluate_deepctr(val_labels, val_pred_ans.transpose(), userid_list, target)\n",
    "\n",
    "    except StopIteration:\n",
    "        loop=False\n",
    "        print('Finished all train')\n",
    "\n",
    "if ONLINE_FLAG:\n",
    "    t1 = time()\n",
    "    pred_ans = train_model.predict(test_model_input, batch_size=batch_size * 20)\n",
    "    pred_ans = pred_ans.transpose()\n",
    "    t2 = time()\n",
    "    print('7个目标行为%d条样本预测耗时（毫秒）：%.3f' % (len(test), (t2 - t1) * 1000.0))\n",
    "    ts = (t2 - t1) * 1000.0* 2000 / (len(test)*7.0) \n",
    "    print('7个目标行为2000条样本平均预测耗时（毫秒）：%.3f' % ts)\n",
    "\n",
    "    # # 5.生成提交文件\n",
    "    for i, action in enumerate(target):\n",
    "        test[action] = pred_ans[i]\n",
    "    test['userid'] = userid_map.inverse_transform(test['userid'])\n",
    "    test[['userid', 'feedid'] + target].to_csv(SUBMIT_DIR + '/mmoe_cin_multi_user_tag_key.csv', index=None, float_format='%.6f')\n",
    "    print('to_csv ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23eb35a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bgm_song_id', (0, 1)),\n",
       "             ('bgm_singer_id', (1, 2)),\n",
       "             ('userid', (2, 3)),\n",
       "             ('feedid', (3, 4)),\n",
       "             ('authorid', (4, 5)),\n",
       "             ('videoplayseconds', (5, 6)),\n",
       "             ('hist_tagids', (6, 17)),\n",
       "             ('tag_seq_len', (17, 18)),\n",
       "             ('hist_keyids', (18, 29)),\n",
       "             ('key_seq_len', (29, 30)),\n",
       "             ('tagids', (30, 31)),\n",
       "             ('keyids', (31, 32)),\n",
       "             ('user_embedding_normal', (32, 33)),\n",
       "             ('user_embedding_adjust', (33, 34))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9345912c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1575"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3664 - 2089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c459fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10800"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14464-3664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21aa38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
